인공지능

하나의 문제를 해결하기 위해는 몇개의 알고리즘을 사용하고 
변수의 특성 ,데이터의 개수, 노이즈 데이터의 양 클래스가 선형적으로 구분 여부

머신러닝 알고리즘 훈련을 위한 단계 
1.변수를 선택하고 훈련 데이터를 수집
2.모델의 성능 지표를 선택 
3.분류 모델과 최적화 알고리즘을 선택 
4.모델의 성능 평가
5.모델 튜닝

머신러닝을 할때는 한가지 알고리즘 으로 모델을 평가하는게 아니라 
여러개의 알고리즘으로 모델을 평가하여 

퍼셉트론 
여러개의 입력을 받아 각각의 값에 가중치를 곱한후 다 더한것이 출력 값이다.

데이터가 다양하면 선형분리 불가능 문제 하나의 선으로 구분할수가 없다. 
-> 치명적 단점 

분류문제를 해결하는것이 로지스틱 회귀이다. 
분류를 확률로 생각하는 방식이다. 
어느 클래스에 분류 되는지 구하는것이다. 

f(x) = 1/1+e^-z 

로지스틱 시그모이드 함수 
함수 모형이 S 자 형태를 띄우기도 하고 

z = W^T x (w:가중치 백터  , x: 입력 데이터 변수 T: 전치 행렬 )
z = 가중치 * 데이터의 값 으로 이루어져있습니다.

z = w0x0 +w1x1+.... + wnxn 가중치와 데이터의 곱을 합으로 이루어져있음


시그모이도 함수를 구현해보면 0~1 사이의 값이 나오게 되면서 이를 확률처럼 사용할수 
있다. 함수의 중간값은 0.5이다.

w^tx = 0
f(x) = 0.5

시그모이드 함수의 특징은 f(x) >= 0.5 z>0

f(x) <0.5 z<0

두가지 중 하나로 구분되는게 결정 경계 라고 한다.
매개변수를 임의로 설정하면 잘 안나온다

알맞은 매개변수를 구하기 위해 
1.목적함수 정의 
2.미분 알맞은 
3.매개변수를 정의 해야 한다.

차수를 늘려 곡선 형태를 표현해야 한다. 

서포트 백터 머신(Support Vector Machine)
마진을 최대화 하는 것이다 
레이블을 구분하기 위한 초평면 결정 경계를 구하는것인데
마진을 최대화 하는것이 목적 이고  결정 경계 안에 서포트 벡터 를 찾은 다음에

일반화를 진행할떄 오차가 낮아지는 경향이 있는것이 발생 한다.

장점으로는 
선형 으로 문제를 해결하지 못할때 2차원 의 문제를 3차원의 문제로 바꾼다음에 
분류를층으로 한다음에, 다시 2차원 으로 바꾸면서 비선형 결정 경계로 바꾼 것이다. 


단점
계산 비용 
3차원으로 분포를 할때 데이터가 하나더 필요하고 상당한 컴퓨팅 파워가 필요하는 단점이 생긴다.

이렇게 복잡한 방법을 절감 하고자 새로운 특성 커널 기법을 사용한다.
