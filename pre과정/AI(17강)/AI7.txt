경사 하강법과 미분 

머신러닝의 적용 - 함수를 만드는 것이다 

그래프를 통해 하나의 선이나 곡선을 그려 최대한 맞춰 보는것이다 

1차함수 
y = ax + b

a,b를 찾아야 한.

과거의 관측을 기반으로 새로운 샘플의 결과값을 예측 해야 한다는 것이가 

적합한 가중치와 절편을 탐색해 
실제 결과값 과 예측 결과값의 차이를 찾아 0 을 만드는 것이다

즉 쉽게 말해서 결과 값 - 예측값 = 0 이 되어야 한다. 

목적 함수  =  ∑1/2(실제 결과값 - 예측 결과값) ^2
: 모든점에서 생기는 오차의 합계가 가능한 작아지는 함수를 찾는것이다. 

최적화 문제 라고도 한다 
제곱을 하는 이유는 : 음수 값이 나오면서 차이를 구하면서 0에 값에 가까워 진다. 

y = x^2

이차 함수 가 있을때 x 는 0 일떄 최소가 된다 

y = 1/2x^2 으로 해도 옆으로만 넓어지고 최솟값은 항상 0 이다.

만약 목적함수의 값의 오차가 커지면 가중치와 절편을 조절해 나가야 한다.


경사 하강법
목적함수의 값을 최소화 시키기 위해 마치 경사를 내려가듯 최소값을 찾는 기법이다.

미분이 필수이다. 
어떤 구간에서의 그래프의 기울기를 구하는것이다. 
이때 간격은 정말 세밀한 차이로도 해도된다.

f(x) = f(x+h) - f(x) / h

d/d(x) * f(x) = lim f(x+h) - f(x) / h
            h->0

미분을 통해 목적함수가 최소가되는 움직임을 찾아야 낸다 

도함수 : 미분후에 나온식을 말한다. 

학습률 에타라는 그리스 문자를 양의 정수를 사용한다 
최솟값에 도달할때까지  갱신해야 하는 횟수가 달라지며
수렴되는 속도가 달라진다 
x = x - n d/dx g(x)

학습률이 낮아지면 수렴은 잘하지만 수렴 하기 까지 많은 시간이 걸린다.
학습률이 너무 커지면 최솟값에서 멀어지는 발산 하는 현상이 발생한다.


편미분 

